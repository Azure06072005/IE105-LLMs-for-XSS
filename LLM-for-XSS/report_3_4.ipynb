{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ba26da",
   "metadata": {},
   "source": [
    "# 3.4 — Complexity of (LLM-style) Obfuscated XSS (Reproduction + Improvements)\n",
    "\n",
    "Notebook này tái hiện ý tưởng **mục 3.4** trong paper: dùng **Shannon entropy** để đo “độ phức tạp/khó đoán” của payload obfuscated,\n",
    "và **cải tiến** bằng cách bổ sung:\n",
    "- **Token-level entropy**\n",
    "- **Compressibility ratio (gzip)**\n",
    "- Các proxy cấu trúc đơn giản: length, non-alnum ratio, unique-char ratio\n",
    "- **Heuristic validity** (balanced brackets/quotes) và báo cáo riêng trên subset “valid-like”\n",
    "- **Bootstrap CI** cho chênh lệch entropy (độ tin cậy thống kê)\n",
    "- **Sensitivity analysis**: baseline tool có/không Base64 (vì Base64 làm entropy tăng mạnh)\n",
    "\n",
    "> Lưu ý: dataset “LLM-style” ở đây là **string-transform composition** để mô phỏng output đa dạng; không tạo payload khai thác chạy được.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e836141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3872, 2), (3872, 4), (6800, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re, math, gzip, io, random, base64, urllib.parse\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load available datasets\n",
    "test_csv = Path(\"./Dataset/_outputs_train_val_test/test.csv\")\n",
    "tool_single_csv = Path(\"./Dataset/test_obfuscated_safe.csv\")  # single-variant tool-like (safe)\n",
    "tool_multi_csv = Path(\"./Dataset/test_obfuscated_safe_multi.csv\")  # multi-variant tool-like (safe)\n",
    "\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_tool_single = pd.read_csv(tool_single_csv) if tool_single_csv.exists() else None\n",
    "df_tool_multi = pd.read_csv(tool_multi_csv)\n",
    "\n",
    "df_test.shape, (df_tool_single.shape if df_tool_single is not None else None), df_tool_multi.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87154995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('report_3_4/obf_tool_baseline_for_3_4.csv'),\n",
       " WindowsPath('report_3_4/obf_llm_style_t1_0_for_3_4.csv'),\n",
       " WindowsPath('report_3_4/obf_llm_style_t1_5_for_3_4.csv'),\n",
       " (3872, 6),\n",
       " (3872, 6),\n",
       " (3872, 6),\n",
       " {0: 2408, 1: 1464})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Safe LLM-style obfuscation generator (string-only)\n",
    "# ----------------------------\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = str(s).replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def b64_encode_only(s: str) -> str:\n",
    "    return base64.b64encode(s.encode(\"utf-8\", errors=\"ignore\")).decode(\"ascii\")\n",
    "\n",
    "def url_encode_only(s: str) -> str:\n",
    "    return urllib.parse.quote(s, safe=\"\")\n",
    "\n",
    "def html_entity_encode(s: str) -> str:\n",
    "    return (s.replace(\"&\",\"&amp;\")\n",
    "             .replace(\"<\",\"&lt;\")\n",
    "             .replace(\">\",\"&gt;\")\n",
    "             .replace('\"',\"&quot;\")\n",
    "             .replace(\"'\",\"&#x27;\"))\n",
    "\n",
    "def whitespace_noise(s: str, p: float = 0.15) -> str:\n",
    "    out=[]\n",
    "    for ch in s:\n",
    "        out.append(ch)\n",
    "        if ch in ['<','>','=',\"'\",'\"','(',')',';','/','+','-','*',',',':'] and random.random()<p:\n",
    "            out.append(\" \" * random.randint(1,2))\n",
    "    return \"\".join(out)\n",
    "\n",
    "def comment_marker(s: str, p: float = 0.03) -> str:\n",
    "    out=[]\n",
    "    for ch in s:\n",
    "        out.append(ch)\n",
    "        if ch.isalpha() and random.random()<p:\n",
    "            out.append(\"/*OBF*/\")\n",
    "    return \"\".join(out)\n",
    "\n",
    "def reverse_chunks(s: str) -> str:\n",
    "    s = str(s)\n",
    "    if len(s) < 12:\n",
    "        return s[::-1]\n",
    "    k = max(3, min(8, len(s)//10))\n",
    "    chunks = [s[i:i+k] for i in range(0, len(s), k)]\n",
    "    return \"\".join(chunks[::-1])\n",
    "\n",
    "def double_urlencode(s: str) -> str:\n",
    "    return url_encode_only(url_encode_only(s))\n",
    "\n",
    "def html_then_urlencode(s: str) -> str:\n",
    "    return url_encode_only(html_entity_encode(s))\n",
    "\n",
    "TRANSFORMS = {\n",
    "    \"urlencode\": url_encode_only,\n",
    "    \"double_urlencode\": double_urlencode,\n",
    "    \"base64\": b64_encode_only,\n",
    "    \"html_entities\": html_entity_encode,\n",
    "    \"html_then_urlencode\": html_then_urlencode,\n",
    "    \"whitespace_noise\": whitespace_noise,\n",
    "    \"comment_marker\": comment_marker,\n",
    "    \"reverse_chunks\": reverse_chunks,\n",
    "}\n",
    "\n",
    "# Probabilities for a \"tool baseline\" (single transform) and for \"LLM-style\" (composed)\n",
    "P_TOOL = {\n",
    "    \"urlencode\": 0.25,\n",
    "    \"base64\": 0.20,\n",
    "    \"html_entities\": 0.20,\n",
    "    \"whitespace_noise\": 0.20,\n",
    "    \"comment_marker\": 0.15,\n",
    "    \"double_urlencode\": 0.00,\n",
    "    \"html_then_urlencode\": 0.00,\n",
    "    \"reverse_chunks\": 0.00,\n",
    "}\n",
    "\n",
    "P_LLM = {\n",
    "    \"urlencode\": 0.18,\n",
    "    \"double_urlencode\": 0.10,\n",
    "    \"base64\": 0.18,\n",
    "    \"html_entities\": 0.12,\n",
    "    \"html_then_urlencode\": 0.10,\n",
    "    \"whitespace_noise\": 0.15,\n",
    "    \"comment_marker\": 0.10,\n",
    "    \"reverse_chunks\": 0.07,\n",
    "}\n",
    "\n",
    "def _sample_weighted(dist: dict) -> str:\n",
    "    names = [k for k,v in dist.items() if v>0]\n",
    "    weights = np.array([dist[k] for k in names], dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    return np.random.choice(names, p=weights)\n",
    "\n",
    "def _sample_k_without_replacement(dist: dict, k: int) -> list:\n",
    "    names = [k for k,v in dist.items() if v>0]\n",
    "    w = np.array([dist[k] for k in names], dtype=float)\n",
    "    w = w / w.sum()\n",
    "    k = min(k, len(names))\n",
    "    chosen=[]\n",
    "    available = names.copy()\n",
    "    avail_w = w.copy()\n",
    "    for _ in range(k):\n",
    "        avail_w = avail_w / avail_w.sum()\n",
    "        pick = np.random.choice(available, p=avail_w)\n",
    "        chosen.append(pick)\n",
    "        j = available.index(pick)\n",
    "        available.pop(j)\n",
    "        avail_w = np.delete(avail_w, j)\n",
    "    return chosen\n",
    "\n",
    "def llm_style_obfuscate(s: str, temperature: float = 1.0) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    temperature >1: more aggressive composition/noise\n",
    "    Returns: (obf_string, recipe)\n",
    "    \"\"\"\n",
    "    s = normalize_text(s)\n",
    "\n",
    "    # decide number of transformations: 1..3\n",
    "    # higher temperature -> higher chance of 2-3 transforms\n",
    "    r = np.random.random()\n",
    "    if temperature <= 1.0:\n",
    "        k = 1 if r < 0.65 else (2 if r < 0.95 else 3)\n",
    "    else:\n",
    "        k = 1 if r < 0.35 else (2 if r < 0.80 else 3)\n",
    "\n",
    "    techs = _sample_k_without_replacement(P_LLM, k)\n",
    "\n",
    "    out = s\n",
    "    # apply in sampled order\n",
    "    for t in techs:\n",
    "        fn = TRANSFORMS[t]\n",
    "        out = fn(out)\n",
    "\n",
    "    # extra \"diversity noise\" when temperature high (still string-only)\n",
    "    if temperature > 1.2:\n",
    "        # sprinkle whitespace + markers lightly\n",
    "        out = whitespace_noise(out, p=0.08)\n",
    "        if np.random.random() < 0.35:\n",
    "            out = comment_marker(out, p=0.015)\n",
    "\n",
    "    return out, \"+\".join(techs)\n",
    "\n",
    "# Generate two LLM-style datasets (temp 1.0 and 1.5) with 1 variant per malicious\n",
    "def build_llm_style_dataset(df_base: pd.DataFrame, temperature: float, seed: int = 42) -> pd.DataFrame:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    rows=[]\n",
    "    for i, r in df_base.iterrows():\n",
    "        payload = str(r[\"payload\"])\n",
    "        label = int(r[\"label\"])\n",
    "        if label != 1:\n",
    "            rows.append({\"sample_id\": i, \"label\": label, \"payload_original\": payload,\n",
    "                         \"payload_obfuscated\": payload, \"generator\": f\"llm_style_t{temperature}\", \"recipe\":\"none\"})\n",
    "        else:\n",
    "            obf, recipe = llm_style_obfuscate(payload, temperature=temperature)\n",
    "            rows.append({\"sample_id\": i, \"label\": label, \"payload_original\": payload,\n",
    "                         \"payload_obfuscated\": obf, \"generator\": f\"llm_style_t{temperature}\", \"recipe\": recipe})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_llm_t10 = build_llm_style_dataset(df_test, temperature=1.0, seed=42)\n",
    "df_llm_t15 = build_llm_style_dataset(df_test, temperature=1.5, seed=42)\n",
    "\n",
    "# baseline tool-like dataset (use existing single dataset if available; otherwise generate)\n",
    "if df_tool_single is not None:\n",
    "    df_tool = df_tool_single.rename(columns={\"payload_obfuscated\":\"payload_obfuscated\"})\n",
    "    # align columns\n",
    "    df_tool = pd.DataFrame({\n",
    "        \"sample_id\": np.arange(len(df_tool)),\n",
    "        \"label\": df_tool[\"label\"].astype(int),\n",
    "        \"payload_original\": df_tool[\"payload_original\"].astype(str),\n",
    "        \"payload_obfuscated\": df_tool[\"payload_obfuscated\"].astype(str),\n",
    "        \"generator\": \"tool_baseline\",\n",
    "        \"recipe\": df_tool[\"technique\"].astype(str),\n",
    "    })\n",
    "else:\n",
    "    # fallback: generate single-transform baseline from test\n",
    "    random.seed(42); np.random.seed(42)\n",
    "    rows=[]\n",
    "    for i, r in df_test.iterrows():\n",
    "        payload=str(r[\"payload\"]); label=int(r[\"label\"])\n",
    "        if label!=1:\n",
    "            rows.append({\"sample_id\":i,\"label\":label,\"payload_original\":payload,\n",
    "                         \"payload_obfuscated\":payload,\"generator\":\"tool_baseline\",\"recipe\":\"none\"})\n",
    "        else:\n",
    "            t = _sample_weighted(P_TOOL)\n",
    "            obf = TRANSFORMS[t](payload)\n",
    "            rows.append({\"sample_id\":i,\"label\":label,\"payload_original\":payload,\n",
    "                         \"payload_obfuscated\":obf,\"generator\":\"tool_baseline\",\"recipe\":t})\n",
    "    df_tool = pd.DataFrame(rows)\n",
    "\n",
    "# Save these datasets for reference\n",
    "out_tool = Path(\"./report_3_4/obf_tool_baseline_for_3_4.csv\")\n",
    "out_t10 = Path(\"./report_3_4/obf_llm_style_t1_0_for_3_4.csv\")\n",
    "out_t15 = Path(\"./report_3_4/obf_llm_style_t1_5_for_3_4.csv\")\n",
    "\n",
    "df_tool.to_csv(out_tool, index=False)\n",
    "df_llm_t10.to_csv(out_t10, index=False)\n",
    "df_llm_t15.to_csv(out_t15, index=False)\n",
    "\n",
    "(out_tool, out_t10, out_t15, df_tool.shape, df_llm_t10.shape, df_llm_t15.shape, df_tool[\"label\"].value_counts().to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e4c9c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11616, 11),\n",
       " (4392, 11),\n",
       " {'tool_baseline': 1464, 'llm_style_t1.0': 1464, 'llm_style_t1.5': 1464})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Complexity metrics (3.4 reproduction + improvements)\n",
    "# ----------------------------\n",
    "def shannon_entropy_char(s: str) -> float:\n",
    "    s = s if s is not None else \"\"\n",
    "    if len(s) == 0:\n",
    "        return 0.0\n",
    "    # counts over characters\n",
    "    counts = {}\n",
    "    for ch in s:\n",
    "        counts[ch] = counts.get(ch, 0) + 1\n",
    "    n = len(s)\n",
    "    ent = 0.0\n",
    "    for c in counts.values():\n",
    "        p = c / n\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent  # bits per char\n",
    "\n",
    "def shannon_entropy_tokens(s: str) -> float:\n",
    "    toks = re.findall(r\"(?u)\\b\\w+\\b\", s.lower() if s else \"\")\n",
    "    if len(toks) <= 1:\n",
    "        return 0.0\n",
    "    counts = {}\n",
    "    for t in toks:\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    n = len(toks)\n",
    "    ent = 0.0\n",
    "    for c in counts.values():\n",
    "        p = c / n\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent  # bits per token\n",
    "\n",
    "def gzip_ratio(s: str) -> float:\n",
    "    b = (s or \"\").encode(\"utf-8\", errors=\"ignore\")\n",
    "    if len(b) == 0:\n",
    "        return 0.0\n",
    "    out = io.BytesIO()\n",
    "    with gzip.GzipFile(fileobj=out, mode=\"wb\") as f:\n",
    "        f.write(b)\n",
    "    comp_len = len(out.getvalue())\n",
    "    return comp_len / max(1, len(b))\n",
    "\n",
    "def unique_char_ratio(s: str) -> float:\n",
    "    s = s or \"\"\n",
    "    return len(set(s)) / max(1, len(s))\n",
    "\n",
    "def non_alnum_ratio(s: str) -> float:\n",
    "    s = s or \"\"\n",
    "    non = sum(1 for ch in s if not ch.isalnum())\n",
    "    return non / max(1, len(s))\n",
    "\n",
    "def balanced_simple(s: str) -> int:\n",
    "    \"\"\"\n",
    "    Heuristic syntactic plausibility:\n",
    "    - parentheses/brackets/braces balanced\n",
    "    - single/double quotes counts even\n",
    "    Returns 1 if passes, else 0\n",
    "    \"\"\"\n",
    "    s = s or \"\"\n",
    "    pairs = {\"(\":\")\",\"[\":\"]\",\"{\":\"}\"}\n",
    "    stack=[]\n",
    "    for ch in s:\n",
    "        if ch in pairs:\n",
    "            stack.append(pairs[ch])\n",
    "        elif ch in pairs.values():\n",
    "            if not stack or stack.pop() != ch:\n",
    "                return 0\n",
    "    if stack:\n",
    "        return 0\n",
    "    # quotes even (very rough)\n",
    "    if s.count(\"'\") % 2 != 0:\n",
    "        return 0\n",
    "    if s.count('\"') % 2 != 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame, group_name: str) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for _, r in df.iterrows():\n",
    "        obf = str(r[\"payload_obfuscated\"])\n",
    "        rows.append({\n",
    "            \"sample_id\": int(r[\"sample_id\"]),\n",
    "            \"label\": int(r[\"label\"]),\n",
    "            \"group\": group_name,\n",
    "            \"length\": len(obf),\n",
    "            \"H_char\": shannon_entropy_char(obf),\n",
    "            \"H_tok\": shannon_entropy_tokens(obf),\n",
    "            \"gzip_ratio\": gzip_ratio(obf),\n",
    "            \"uniq_char_ratio\": unique_char_ratio(obf),\n",
    "            \"non_alnum_ratio\": non_alnum_ratio(obf),\n",
    "            \"balanced\": balanced_simple(obf),\n",
    "            \"recipe\": r.get(\"recipe\",\"\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "m_tool = compute_metrics(df_tool, \"tool_baseline\")\n",
    "m_t10 = compute_metrics(df_llm_t10, \"llm_style_t1.0\")\n",
    "m_t15 = compute_metrics(df_llm_t15, \"llm_style_t1.5\")\n",
    "\n",
    "metrics_all = pd.concat([m_tool, m_t10, m_t15], ignore_index=True)\n",
    "\n",
    "# Focus on malicious only like paper's \"obfuscated XSS\"\n",
    "metrics_mal = metrics_all[metrics_all[\"label\"] == 1].copy()\n",
    "\n",
    "metrics_all.shape, metrics_mal.shape, metrics_mal[\"group\"].value_counts().to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d634fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14544, 11), (7320, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3) Complexity metrics\n",
    "# ----------------------------\n",
    "def shannon_entropy_char(s: str) -> float:\n",
    "    s = s if s is not None else \"\"\n",
    "    if len(s) == 0:\n",
    "        return 0.0\n",
    "    counts = {}\n",
    "    for ch in s:\n",
    "        counts[ch] = counts.get(ch, 0) + 1\n",
    "    n = len(s)\n",
    "    ent = 0.0\n",
    "    for c in counts.values():\n",
    "        p = c / n\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def shannon_entropy_tokens(s: str) -> float:\n",
    "    toks = re.findall(r\"(?u)\\b\\w+\\b\", s.lower() if s else \"\")\n",
    "    if len(toks) <= 1:\n",
    "        return 0.0\n",
    "    counts = {}\n",
    "    for t in toks:\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    n = len(toks)\n",
    "    ent = 0.0\n",
    "    for c in counts.values():\n",
    "        p = c / n\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def gzip_ratio(s: str) -> float:\n",
    "    b = (s or \"\").encode(\"utf-8\", errors=\"ignore\")\n",
    "    if len(b) == 0:\n",
    "        return 0.0\n",
    "    out = io.BytesIO()\n",
    "    with gzip.GzipFile(fileobj=out, mode=\"wb\") as f:\n",
    "        f.write(b)\n",
    "    comp_len = len(out.getvalue())\n",
    "    return comp_len / max(1, len(b))\n",
    "\n",
    "def unique_char_ratio(s: str) -> float:\n",
    "    s = s or \"\"\n",
    "    return len(set(s)) / max(1, len(s))\n",
    "\n",
    "def non_alnum_ratio(s: str) -> float:\n",
    "    s = s or \"\"\n",
    "    non = sum(1 for ch in s if not ch.isalnum())\n",
    "    return non / max(1, len(s))\n",
    "\n",
    "def balanced_simple(s: str) -> int:\n",
    "    s = s or \"\"\n",
    "    pairs = {\"(\":\")\",\"[\":\"]\",\"{\":\"}\"}\n",
    "    stack=[]\n",
    "    for ch in s:\n",
    "        if ch in pairs:\n",
    "            stack.append(pairs[ch])\n",
    "        elif ch in pairs.values():\n",
    "            if not stack or stack.pop() != ch:\n",
    "                return 0\n",
    "    if stack:\n",
    "        return 0\n",
    "    if s.count(\"'\") % 2 != 0:\n",
    "        return 0\n",
    "    if s.count('\"') % 2 != 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for _, r in df.iterrows():\n",
    "        obf = str(r[\"payload_obfuscated\"])\n",
    "        rows.append({\n",
    "            \"sample_id\": int(r[\"sample_id\"]),\n",
    "            \"label\": int(r[\"label\"]),\n",
    "            \"group\": r[\"group\"],\n",
    "            \"length\": len(obf),\n",
    "            \"H_char\": shannon_entropy_char(obf),\n",
    "            \"H_tok\": shannon_entropy_tokens(obf),\n",
    "            \"gzip_ratio\": gzip_ratio(obf),\n",
    "            \"uniq_char_ratio\": unique_char_ratio(obf),\n",
    "            \"non_alnum_ratio\": non_alnum_ratio(obf),\n",
    "            \"balanced\": balanced_simple(obf),\n",
    "            \"recipe\": r.get(\"recipe\",\"\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "m_tool = compute_metrics(df_tool)\n",
    "m_t10 = compute_metrics(df_llm_t10)\n",
    "m_t15 = compute_metrics(df_llm_t15)\n",
    "\n",
    "metrics_all = pd.concat([m_tool, m_t10, m_t15], ignore_index=True)\n",
    "metrics_mal = metrics_all[metrics_all[\"label\"]==1].copy()\n",
    "\n",
    "metrics_all.shape, metrics_mal.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9830a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>H_char_mean</th>\n",
       "      <th>H_char_med</th>\n",
       "      <th>H_tok_mean</th>\n",
       "      <th>gzip_mean</th>\n",
       "      <th>len_mean</th>\n",
       "      <th>uniq_mean</th>\n",
       "      <th>nonalnum_mean</th>\n",
       "      <th>balanced_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llm_style_t1.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.4186</td>\n",
       "      <td>4.3027</td>\n",
       "      <td>2.7472</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>103.7425</td>\n",
       "      <td>0.3516</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm_style_t1.5</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.5064</td>\n",
       "      <td>4.3875</td>\n",
       "      <td>2.7345</td>\n",
       "      <td>1.0239</td>\n",
       "      <td>117.7322</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tool_baseline</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.4384</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>2.6276</td>\n",
       "      <td>1.1601</td>\n",
       "      <td>85.1066</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            group       n  H_char_mean  H_char_med  H_tok_mean  gzip_mean  \\\n",
       "0  llm_style_t1.0  1464.0       4.4186      4.3027      2.7472     1.0602   \n",
       "1  llm_style_t1.5  1464.0       4.5064      4.3875      2.7345     1.0239   \n",
       "2   tool_baseline  1464.0       4.4384      4.3303      2.6276     1.1601   \n",
       "\n",
       "   len_mean  uniq_mean  nonalnum_mean  balanced_rate  \n",
       "0  103.7425     0.3516         0.1618         0.9665  \n",
       "1  117.7322     0.3432         0.1530         0.9693  \n",
       "2   85.1066     0.3926         0.1992         0.9966  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics + bootstrap CI for mean differences\n",
    "def bootstrap_ci_diff(a: np.ndarray, b: np.ndarray, n_boot=5000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a = np.asarray(a); b = np.asarray(b)\n",
    "    diffs = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        sa = rng.choice(a, size=len(a), replace=True)\n",
    "        sb = rng.choice(b, size=len(b), replace=True)\n",
    "        diffs[i] = sb.mean() - sa.mean()  # b - a\n",
    "    lo, hi = np.percentile(diffs, [2.5, 97.5])\n",
    "    return float(diffs.mean()), float(lo), float(hi)\n",
    "\n",
    "def group_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    agg = df.groupby(\"group\").agg(\n",
    "        n=(\"H_char\",\"size\"),\n",
    "        H_char_mean=(\"H_char\",\"mean\"),\n",
    "        H_char_med=(\"H_char\",\"median\"),\n",
    "        H_tok_mean=(\"H_tok\",\"mean\"),\n",
    "        gzip_mean=(\"gzip_ratio\",\"mean\"),\n",
    "        len_mean=(\"length\",\"mean\"),\n",
    "        uniq_mean=(\"uniq_char_ratio\",\"mean\"),\n",
    "        nonalnum_mean=(\"non_alnum_ratio\",\"mean\"),\n",
    "        balanced_rate=(\"balanced\",\"mean\"),\n",
    "    ).reset_index()\n",
    "    return agg\n",
    "\n",
    "sum_mal = group_summary(metrics_mal)\n",
    "sum_mal_rounded = sum_mal.copy()\n",
    "for c in sum_mal_rounded.columns:\n",
    "    if c != \"group\":\n",
    "        sum_mal_rounded[c] = sum_mal_rounded[c].astype(float).round(4)\n",
    "sum_mal_rounded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a308d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>H_char_mean</th>\n",
       "      <th>H_char_med</th>\n",
       "      <th>H_tok_mean</th>\n",
       "      <th>gzip_mean</th>\n",
       "      <th>len_mean</th>\n",
       "      <th>uniq_mean</th>\n",
       "      <th>nonalnum_mean</th>\n",
       "      <th>balanced_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llm_style_t1.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.4186</td>\n",
       "      <td>4.3027</td>\n",
       "      <td>2.7472</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>103.7425</td>\n",
       "      <td>0.3516</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm_style_t1.5</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.5064</td>\n",
       "      <td>4.3875</td>\n",
       "      <td>2.7345</td>\n",
       "      <td>1.0239</td>\n",
       "      <td>117.7322</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tool_baseline</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.4384</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>2.6276</td>\n",
       "      <td>1.1601</td>\n",
       "      <td>85.1066</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tool_no_base64</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4.2842</td>\n",
       "      <td>4.2736</td>\n",
       "      <td>3.1840</td>\n",
       "      <td>1.1431</td>\n",
       "      <td>85.1414</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            group       n  H_char_mean  H_char_med  H_tok_mean  gzip_mean  \\\n",
       "0  llm_style_t1.0  1464.0       4.4186      4.3027      2.7472     1.0602   \n",
       "1  llm_style_t1.5  1464.0       4.5064      4.3875      2.7345     1.0239   \n",
       "2   tool_baseline  1464.0       4.4384      4.3303      2.6276     1.1601   \n",
       "3  tool_no_base64  1464.0       4.2842      4.2736      3.1840     1.1431   \n",
       "\n",
       "   len_mean  uniq_mean  nonalnum_mean  balanced_rate  \n",
       "0  103.7425     0.3516         0.1618         0.9665  \n",
       "1  117.7322     0.3432         0.1530         0.9693  \n",
       "2   85.1066     0.3926         0.1992         0.9966  \n",
       "3   85.1414     0.3611         0.2390         0.9952  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity analysis: tool baseline without base64 (to show how metric depends on obfuscator mix)\n",
    "P_TOOL_NO_B64 = P_TOOL.copy()\n",
    "P_TOOL_NO_B64[\"base64\"] = 0.0\n",
    "# renormalize by sampling function _sample_weighted uses weights >0, so ok.\n",
    "\n",
    "def build_tool_baseline(df_base: pd.DataFrame, dist: dict, seed: int = 42, name: str = \"tool_baseline\") -> pd.DataFrame:\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    rows=[]\n",
    "    for i, r in df_base.iterrows():\n",
    "        payload=str(r[\"payload\"]); label=int(r[\"label\"])\n",
    "        if label!=1:\n",
    "            rows.append({\"sample_id\": i, \"label\": label, \"payload_original\": payload,\n",
    "                         \"payload_obfuscated\": payload, \"generator\": name, \"recipe\":\"none\"})\n",
    "        else:\n",
    "            t = _sample_weighted(dist)\n",
    "            obf = TRANSFORMS[t](payload)\n",
    "            rows.append({\"sample_id\": i, \"label\": label, \"payload_original\": payload,\n",
    "                         \"payload_obfuscated\": obf, \"generator\": name, \"recipe\":t})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_tool_no_b64 = build_tool_baseline(df_test, P_TOOL_NO_B64, seed=42, name=\"tool_no_base64\")\n",
    "m_tool_no_b64 = compute_metrics(df_tool_no_b64, \"tool_no_base64\")\n",
    "metrics_mal2 = pd.concat([metrics_mal, m_tool_no_b64[m_tool_no_b64[\"label\"]==1]], ignore_index=True)\n",
    "\n",
    "sum_mal2 = group_summary(metrics_mal2)\n",
    "sum_mal2_rounded = sum_mal2.copy()\n",
    "for c in sum_mal2_rounded.columns:\n",
    "    if c != \"group\":\n",
    "        sum_mal2_rounded[c] = sum_mal2_rounded[c].astype(float).round(4)\n",
    "sum_mal2_rounded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f677b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_baseline mean(H_char)= 4.438386753753551 LLM= 4.50638427984729 increase%= 1.5320324673426378 boot_diff= 0.0678928031992642 CI=[ 0.03501689992342396 , 0.10063142921668404 ]\n",
      "tool_no_base64 mean(H_char)= 4.284196985406204 LLM= 4.50638427984729 increase%= 5.186206311193206 boot_diff= 0.22201066850471632 CI=[ 0.1941160638047772 , 0.24988429714072766 ]\n"
     ]
    }
   ],
   "source": [
    "def percent_increase(a, b):\n",
    "    return (b - a) / a * 100.0 if a != 0 else np.nan\n",
    "\n",
    "def get_group(df, g):\n",
    "    return df[df[\"group\"]==g]\n",
    "\n",
    "# Compare LLM t1.5 vs tool_baseline and vs tool_no_base64\n",
    "for baseline in [\"tool_baseline\", \"tool_no_base64\"]:\n",
    "    a = get_group(metrics_mal2, baseline)[\"H_char\"].to_numpy()\n",
    "    b = get_group(metrics_mal2, \"llm_style_t1.5\")[\"H_char\"].to_numpy()\n",
    "    mean_diff, lo, hi = bootstrap_ci_diff(a, b, n_boot=3000, seed=42)\n",
    "    inc = percent_increase(a.mean(), b.mean())\n",
    "    print(baseline, \"mean(H_char)=\", a.mean(), \"LLM=\", b.mean(),\n",
    "          \"increase%=\", inc, \"boot_diff=\", mean_diff, \"CI=[\", lo, \",\", hi, \"]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1617cf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>candidate</th>\n",
       "      <th>mean_H_char_baseline</th>\n",
       "      <th>mean_H_char_candidate</th>\n",
       "      <th>percent_increase</th>\n",
       "      <th>boot_mean_diff</th>\n",
       "      <th>boot_CI_low</th>\n",
       "      <th>boot_CI_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tool_baseline</td>\n",
       "      <td>llm_style_t1.0</td>\n",
       "      <td>4.4384</td>\n",
       "      <td>4.4186</td>\n",
       "      <td>-0.4463</td>\n",
       "      <td>-0.0201</td>\n",
       "      <td>-0.0503</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tool_baseline</td>\n",
       "      <td>llm_style_t1.5</td>\n",
       "      <td>4.4384</td>\n",
       "      <td>4.5064</td>\n",
       "      <td>1.5320</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tool_no_base64</td>\n",
       "      <td>llm_style_t1.5</td>\n",
       "      <td>4.2842</td>\n",
       "      <td>4.5064</td>\n",
       "      <td>5.1862</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.2495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         baseline       candidate  mean_H_char_baseline  \\\n",
       "0   tool_baseline  llm_style_t1.0                4.4384   \n",
       "1   tool_baseline  llm_style_t1.5                4.4384   \n",
       "2  tool_no_base64  llm_style_t1.5                4.2842   \n",
       "\n",
       "   mean_H_char_candidate  percent_increase  boot_mean_diff  boot_CI_low  \\\n",
       "0                 4.4186           -0.4463         -0.0201      -0.0503   \n",
       "1                 4.5064            1.5320          0.0679       0.0350   \n",
       "2                 4.5064            5.1862          0.2221       0.1946   \n",
       "\n",
       "   boot_CI_high  \n",
       "0        0.0102  \n",
       "1        0.1009  \n",
       "2        0.2495  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a concise comparison table (malicious only)\n",
    "comparisons = []\n",
    "pairs = [\n",
    "    (\"tool_baseline\", \"llm_style_t1.0\"),\n",
    "    (\"tool_baseline\", \"llm_style_t1.5\"),\n",
    "    (\"tool_no_base64\", \"llm_style_t1.5\"),\n",
    "]\n",
    "for base, llm in pairs:\n",
    "    a = get_group(metrics_mal2, base)[\"H_char\"].to_numpy()\n",
    "    b = get_group(metrics_mal2, llm)[\"H_char\"].to_numpy()\n",
    "    mean_diff, lo, hi = bootstrap_ci_diff(a, b, n_boot=5000, seed=42)\n",
    "    comparisons.append({\n",
    "        \"baseline\": base,\n",
    "        \"candidate\": llm,\n",
    "        \"mean_H_char_baseline\": a.mean(),\n",
    "        \"mean_H_char_candidate\": b.mean(),\n",
    "        \"percent_increase\": percent_increase(a.mean(), b.mean()),\n",
    "        \"boot_mean_diff\": mean_diff,\n",
    "        \"boot_CI_low\": lo,\n",
    "        \"boot_CI_high\": hi,\n",
    "    })\n",
    "\n",
    "df_cmp = pd.DataFrame(comparisons)\n",
    "df_cmp_rounded = df_cmp.copy()\n",
    "for c in df_cmp_rounded.columns:\n",
    "    if c not in [\"baseline\",\"candidate\"]:\n",
    "        df_cmp_rounded[c] = df_cmp_rounded[c].astype(float).round(4)\n",
    "df_cmp_rounded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2370b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_26380\\3386231467.py:12: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(data, labels=[g.replace(\"_\",\" \").upper() for g in order], showfliers=False)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_26380\\3386231467.py:12: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(data, labels=[g.replace(\"_\",\" \").upper() for g in order], showfliers=False)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_26380\\3386231467.py:12: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(data, labels=[g.replace(\"_\",\" \").upper() for g in order], showfliers=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./report_3_4/3_4_entropy_char_boxplot.png',\n",
       " './report_3_4/3_4_entropy_token_boxplot.png',\n",
       " './report_3_4/3_4_gzip_ratio_boxplot.png',\n",
       " '3_4_entropy_char_cdf.png',\n",
       " '3_4_length_vs_entropy_scatter.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "plots = {}\n",
    "\n",
    "# Prepare data for plots (malicious only)\n",
    "order = [\"tool_baseline\", \"tool_no_base64\", \"llm_style_t1.0\", \"llm_style_t1.5\"]\n",
    "plot_df = metrics_mal2[metrics_mal2[\"group\"].isin(order)].copy()\n",
    "\n",
    "def make_boxplot(metric, ylabel, title, out_name):\n",
    "    data = [plot_df[plot_df[\"group\"]==g][metric].to_numpy() for g in order]\n",
    "    fig, ax = plt.subplots(figsize=(10,4.5))\n",
    "    ax.boxplot(data, labels=[g.replace(\"_\",\" \").upper() for g in order], showfliers=False)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.35)\n",
    "    fig.tight_layout()\n",
    "    out_path = Path(\"\") / out_name\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    plots[out_name] = out_path\n",
    "\n",
    "make_boxplot(\"H_char\", \"Entropy (bits/char)\", \"3.4 Complexity — Character-level Shannon Entropy (malicious only)\", \"./report_3_4/3_4_entropy_char_boxplot.png\")\n",
    "make_boxplot(\"H_tok\", \"Entropy (bits/token)\", \"3.4 Complexity — Token-level Shannon Entropy (malicious only)\", \"./report_3_4/3_4_entropy_token_boxplot.png\")\n",
    "make_boxplot(\"gzip_ratio\", \"gzip(compressed)/raw\", \"3.4 Complexity — Compressibility Ratio (malicious only)\", \"./report_3_4/3_4_gzip_ratio_boxplot.png\")\n",
    "\n",
    "# CDF plot for H_char\n",
    "fig, ax = plt.subplots(figsize=(9,4.5))\n",
    "for g in order:\n",
    "    vals = np.sort(plot_df[plot_df[\"group\"]==g][\"H_char\"].to_numpy())\n",
    "    y = np.arange(1, len(vals)+1) / len(vals)\n",
    "    ax.plot(vals, y, label=g.replace(\"_\",\" \").upper())\n",
    "ax.set_xlabel(\"Entropy (bits/char)\")\n",
    "ax.set_ylabel(\"CDF\")\n",
    "ax.set_title(\"3.4 Complexity — CDF of Character Entropy (malicious only)\")\n",
    "ax.grid(alpha=0.35)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "cdf_path = Path(\"./report_3_4/3_4_entropy_char_cdf.png\")\n",
    "fig.savefig(cdf_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "plots[\"3_4_entropy_char_cdf.png\"] = cdf_path\n",
    "\n",
    "# Scatter: length vs H_char (sample a subset for readability)\n",
    "fig, ax = plt.subplots(figsize=(9,4.5))\n",
    "for g in order:\n",
    "    sub = plot_df[plot_df[\"group\"]==g].sample(n=min(600, (plot_df[\"group\"]==g).sum()), random_state=42)\n",
    "    ax.scatter(sub[\"length\"], sub[\"H_char\"], s=8, alpha=0.35, label=g.replace(\"_\",\" \").upper())\n",
    "ax.set_xlabel(\"Length\")\n",
    "ax.set_ylabel(\"Entropy (bits/char)\")\n",
    "ax.set_title(\"3.4 Complexity — Length vs Character Entropy (malicious only)\")\n",
    "ax.grid(alpha=0.35)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "scatter_path = Path(\"./report_3_4/3_4_length_vs_entropy_scatter.png\")\n",
    "fig.savefig(scatter_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "plots[\"3_4_length_vs_entropy_scatter.png\"] = scatter_path\n",
    "\n",
    "list(plots.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f636b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
