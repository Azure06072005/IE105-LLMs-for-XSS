{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c0e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13938, 2),\n",
       " (3872, 2),\n",
       " (6800, 6),\n",
       " ['payload', 'label'],\n",
       " ['sample_id',\n",
       "  'variant_id',\n",
       "  'technique',\n",
       "  'payload_original',\n",
       "  'payload_obfuscated',\n",
       "  'label'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "from pathlib import Path\n",
    "\n",
    "train_path = Path(\"./Dataset/_outputs_train_val_test/train.csv\")\n",
    "val_path = Path(\"./Dataset/_outputs_train_val_test/val.csv\")\n",
    "test_path = Path(\"./Dataset/_outputs_train_val_test/test.csv\")\n",
    "obf_path = Path(\"./Dataset/test_obfuscated_safe_multi.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path) if val_path.exists() else None\n",
    "test_df = pd.read_csv(test_path)\n",
    "obf_df = pd.read_csv(obf_path)\n",
    "\n",
    "train_df.shape, test_df.shape, obf_df.shape, train_df.columns.tolist(), obf_df.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e77fa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM (BoW full)</td>\n",
       "      <td>0.613235</td>\n",
       "      <td>0.996618</td>\n",
       "      <td>0.402550</td>\n",
       "      <td>0.573467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression (BoW full)</td>\n",
       "      <td>0.611618</td>\n",
       "      <td>0.996597</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.570918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (chi2 k=500)</td>\n",
       "      <td>0.611029</td>\n",
       "      <td>0.994901</td>\n",
       "      <td>0.399818</td>\n",
       "      <td>0.570408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree (chi2 k=500)</td>\n",
       "      <td>0.604559</td>\n",
       "      <td>0.989649</td>\n",
       "      <td>0.391849</td>\n",
       "      <td>0.561409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model       acc      prec       rec        f1\n",
       "0           Linear SVM (BoW full)  0.613235  0.996618  0.402550  0.573467\n",
       "1  Logistic Regression (BoW full)  0.611618  0.996597  0.400046  0.570918\n",
       "2      Random Forest (chi2 k=500)  0.611029  0.994901  0.399818  0.570408\n",
       "3      Decision Tree (chi2 k=500)  0.604559  0.989649  0.391849  0.561409"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = str(s).lower()\n",
    "    s = s.replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Clean payloads\n",
    "for df in [train_df, test_df]:\n",
    "    df[\"payload\"] = df[\"payload\"].map(normalize_text)\n",
    "obf_df[\"payload_obfuscated\"] = obf_df[\"payload_obfuscated\"].map(normalize_text)\n",
    "\n",
    "y_train = train_df[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "# Fit BoW on train only (paper-style)\n",
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X_train = vectorizer.fit_transform(train_df[\"payload\"])\n",
    "\n",
    "# Transform obfuscated payloads\n",
    "X_obf_full = vectorizer.transform(obf_df[\"payload_obfuscated\"])\n",
    "y_obf = obf_df[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "# Build chi2 selector for tree-based models\n",
    "TOP_K = 500\n",
    "selector = SelectKBest(score_func=chi2, k=min(TOP_K, X_train.shape[1]))\n",
    "X_train_k = selector.fit_transform(X_train, y_train)\n",
    "X_obf_k = selector.transform(X_obf_full)\n",
    "\n",
    "# Models (match your model_selection style)\n",
    "RANDOM_STATE = 42\n",
    "models = {\n",
    "    \"Logistic Regression (BoW full)\": (\"full\",\n",
    "        LogisticRegression(max_iter=2000, n_jobs=-1, class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
    "    \"Linear SVM (BoW full)\": (\"full\",\n",
    "        LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
    "    f\"Decision Tree (chi2 k={selector.k})\": (\"k\",\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
    "    f\"Random Forest (chi2 k={selector.k})\": (\"k\",\n",
    "        RandomForestClassifier(n_estimators=300, n_jobs=-1, class_weight=\"balanced_subsample\", random_state=RANDOM_STATE)),\n",
    "}\n",
    "\n",
    "# Fit\n",
    "fitted = {}\n",
    "for name, (space, clf) in models.items():\n",
    "    if space == \"full\":\n",
    "        clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train_k, y_train)\n",
    "    fitted[name] = (space, clf)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"prec\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"rec\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "# 1) Mean metrics across variants (evaluate on all rows in obf_df)\n",
    "mean_rows = []\n",
    "pred_cache = {}  # store per-row predictions for later\n",
    "for name, (space, clf) in fitted.items():\n",
    "    X_use = X_obf_full if space == \"full\" else X_obf_k\n",
    "    y_pred = clf.predict(X_use)\n",
    "    pred_cache[name] = y_pred\n",
    "    m = metrics(y_obf, y_pred)\n",
    "    mean_rows.append({\"model\": name, **m})\n",
    "\n",
    "df_mean = pd.DataFrame(mean_rows).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
    "df_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a0de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>samples</th>\n",
       "      <th>avg_variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM (BoW full)</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>3872</td>\n",
       "      <td>1.756198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (chi2 k=500)</td>\n",
       "      <td>0.629132</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.049007</td>\n",
       "      <td>3872</td>\n",
       "      <td>1.756198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression (BoW full)</td>\n",
       "      <td>0.628874</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>0.043912</td>\n",
       "      <td>3872</td>\n",
       "      <td>1.756198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree (chi2 k=500)</td>\n",
       "      <td>0.625775</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>3872</td>\n",
       "      <td>1.756198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model       acc      prec       rec        f1  \\\n",
       "0           Linear SVM (BoW full)  0.630682  0.869565  0.027322  0.052980   \n",
       "1      Random Forest (chi2 k=500)  0.629132  0.804348  0.025273  0.049007   \n",
       "2  Logistic Regression (BoW full)  0.628874  0.846154  0.022541  0.043912   \n",
       "3      Decision Tree (chi2 k=500)  0.625775  0.647059  0.022541  0.043564   \n",
       "\n",
       "   samples  avg_variants  \n",
       "0     3872      1.756198  \n",
       "1     3872      1.756198  \n",
       "2     3872      1.756198  \n",
       "3     3872      1.756198  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Worst-case robustness (per original sample_id)\n",
    "worst_rows = []\n",
    "for name, y_pred in pred_cache.items():\n",
    "    tmp = obf_df[[\"sample_id\",\"label\"]].copy()\n",
    "    tmp[\"pred\"] = y_pred.astype(int)\n",
    "\n",
    "    # group per sample_id\n",
    "    # For malicious (label=1): worst-case pred = min over variants\n",
    "    # For benign (label=0): only one row, min is fine too\n",
    "    grp = tmp.groupby(\"sample_id\", as_index=False).agg(\n",
    "        y_true=(\"label\", \"max\"),  # should be 0 for benign, 1 for malicious\n",
    "        y_pred=(\"pred\", \"min\"),   # worst-case (if any variant missed -> 0)\n",
    "        n=(\"pred\",\"size\")\n",
    "    )\n",
    "    m = metrics(grp[\"y_true\"].to_numpy(), grp[\"y_pred\"].to_numpy())\n",
    "    worst_rows.append({\"model\": name, **m, \"samples\": len(grp), \"avg_variants\": grp[\"n\"].mean()})\n",
    "    \n",
    "df_worst = pd.DataFrame(worst_rows).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
    "df_worst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee3fb291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                            model worst_technique  mal_recall   f1  \\\n",
       " 0      Decision Tree (chi2 k=500)          base64         0.0  0.0   \n",
       " 1           Linear SVM (BoW full)          base64         0.0  0.0   \n",
       " 2  Logistic Regression (BoW full)          base64         0.0  0.0   \n",
       " 3      Random Forest (chi2 k=500)          base64         0.0  0.0   \n",
       " \n",
       "    n_malicious  \n",
       " 0          814  \n",
       " 1          814  \n",
       " 2          814  \n",
       " 3          814  ,\n",
       " model                Decision Tree (chi2 k=500)  Linear SVM (BoW full)  \\\n",
       " technique                                                                \n",
       " base64                                 0.000000               0.000000   \n",
       " comment_marker                         0.893246               0.978214   \n",
       " double_urlencode                       0.012526               0.016701   \n",
       " html_entities                          0.993912               0.995434   \n",
       " html_then_urlencode                    0.012048               0.012048   \n",
       " urlencode                              0.009512               0.011891   \n",
       " whitespace_noise                       0.990683               0.995342   \n",
       " \n",
       " model                Logistic Regression (BoW full)  \\\n",
       " technique                                             \n",
       " base64                                     0.000000   \n",
       " comment_marker                             0.980392   \n",
       " double_urlencode                           0.004175   \n",
       " html_entities                              0.992390   \n",
       " html_then_urlencode                        0.002008   \n",
       " urlencode                                  0.010702   \n",
       " whitespace_noise                           0.998447   \n",
       " \n",
       " model                Random Forest (chi2 k=500)  \n",
       " technique                                        \n",
       " base64                                 0.000000  \n",
       " comment_marker                         0.971678  \n",
       " double_urlencode                       0.010438  \n",
       " html_entities                          0.995434  \n",
       " html_then_urlencode                    0.010040  \n",
       " urlencode                              0.007134  \n",
       " whitespace_noise                       0.993789  )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Per-technique breakdown:\n",
    "# For each technique t != 'none', build a test set = benign rows + malicious rows of technique t\n",
    "benign_mask = (obf_df[\"label\"] == 0)\n",
    "benign_idx = np.where(benign_mask.to_numpy())[0]\n",
    "\n",
    "techniques = sorted([t for t in obf_df[\"technique\"].unique().tolist() if t != \"none\"])\n",
    "\n",
    "tech_rows = []\n",
    "for name, (space, clf) in fitted.items():\n",
    "    y_pred_all = pred_cache[name].astype(int)\n",
    "\n",
    "    for t in techniques:\n",
    "        mal_mask_t = (obf_df[\"label\"] == 1) & (obf_df[\"technique\"] == t)\n",
    "        idx = np.concatenate([benign_idx, np.where(mal_mask_t.to_numpy())[0]])\n",
    "        y_true_t = y_obf[idx]\n",
    "        y_pred_t = y_pred_all[idx]\n",
    "        m = metrics(y_true_t, y_pred_t)\n",
    "\n",
    "        # Also compute recall on malicious only (same as m[\"rec\"], but keep explicit)\n",
    "        mal_only_idx = np.where(mal_mask_t.to_numpy())[0]\n",
    "        y_true_mal = y_obf[mal_only_idx]\n",
    "        y_pred_mal = y_pred_all[mal_only_idx]\n",
    "        rec_mal = recall_score(y_true_mal, y_pred_mal, zero_division=0)\n",
    "\n",
    "        tech_rows.append({\n",
    "            \"model\": name,\n",
    "            \"technique\": t,\n",
    "            \"n_benign\": len(benign_idx),\n",
    "            \"n_malicious\": len(mal_only_idx),\n",
    "            \"acc\": m[\"acc\"],\n",
    "            \"prec\": m[\"prec\"],\n",
    "            \"rec\": m[\"rec\"],      # recall over full set (same as malicious recall because benign are 0)\n",
    "            \"f1\": m[\"f1\"],\n",
    "            \"mal_recall\": rec_mal,\n",
    "        })\n",
    "\n",
    "df_tech = pd.DataFrame(tech_rows)\n",
    "\n",
    "# For \"kỹ thuật nào làm tụt recall nhất\": find min mal_recall per model\n",
    "df_worst_tech = (\n",
    "    df_tech.sort_values([\"model\",\"mal_recall\",\"f1\"], ascending=[True, True, True])\n",
    "           .groupby(\"model\", as_index=False)\n",
    "           .first()[[\"model\",\"technique\",\"mal_recall\",\"f1\",\"n_malicious\"]]\n",
    "           .rename(columns={\"technique\":\"worst_technique\"})\n",
    ")\n",
    "\n",
    "# Also provide a pivot table of mal_recall per technique for easy viewing\n",
    "pivot_recall = df_tech.pivot_table(index=\"technique\", columns=\"model\", values=\"mal_recall\", aggfunc=\"mean\")\n",
    "df_worst_tech, pivot_recall.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031d9f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean metrics over all obfuscated variants (expanded test)                             model     acc    prec     rec      f1\n",
      "0           Linear SVM (BoW full)  0.6132  0.9966  0.4026  0.5735\n",
      "1  Logistic Regression (BoW full)  0.6116  0.9966  0.4000  0.5709\n",
      "2      Random Forest (chi2 k=500)  0.6110  0.9949  0.3998  0.5704\n",
      "3      Decision Tree (chi2 k=500)  0.6046  0.9896  0.3918  0.5614\n",
      "Worst-case robustness (per original sample_id; malicious must pass all variants)                             model     acc    prec     rec      f1  samples  \\\n",
      "0           Linear SVM (BoW full)  0.6307  0.8696  0.0273  0.0530     3872   \n",
      "1      Random Forest (chi2 k=500)  0.6291  0.8043  0.0253  0.0490     3872   \n",
      "2  Logistic Regression (BoW full)  0.6289  0.8462  0.0225  0.0439     3872   \n",
      "3      Decision Tree (chi2 k=500)  0.6258  0.6471  0.0225  0.0436     3872   \n",
      "\n",
      "   avg_variants  \n",
      "0        1.7562  \n",
      "1        1.7562  \n",
      "2        1.7562  \n",
      "3        1.7562  \n",
      "Per-technique breakdown (benign + malicious of that technique)                              model            technique  n_benign  \\\n",
      "14      Decision Tree (chi2 k=500)               base64      2408   \n",
      "19      Decision Tree (chi2 k=500)            urlencode      2408   \n",
      "18      Decision Tree (chi2 k=500)  html_then_urlencode      2408   \n",
      "16      Decision Tree (chi2 k=500)     double_urlencode      2408   \n",
      "15      Decision Tree (chi2 k=500)       comment_marker      2408   \n",
      "20      Decision Tree (chi2 k=500)     whitespace_noise      2408   \n",
      "17      Decision Tree (chi2 k=500)        html_entities      2408   \n",
      "7            Linear SVM (BoW full)               base64      2408   \n",
      "12           Linear SVM (BoW full)            urlencode      2408   \n",
      "11           Linear SVM (BoW full)  html_then_urlencode      2408   \n",
      "9            Linear SVM (BoW full)     double_urlencode      2408   \n",
      "8            Linear SVM (BoW full)       comment_marker      2408   \n",
      "13           Linear SVM (BoW full)     whitespace_noise      2408   \n",
      "10           Linear SVM (BoW full)        html_entities      2408   \n",
      "0   Logistic Regression (BoW full)               base64      2408   \n",
      "4   Logistic Regression (BoW full)  html_then_urlencode      2408   \n",
      "2   Logistic Regression (BoW full)     double_urlencode      2408   \n",
      "5   Logistic Regression (BoW full)            urlencode      2408   \n",
      "1   Logistic Regression (BoW full)       comment_marker      2408   \n",
      "3   Logistic Regression (BoW full)        html_entities      2408   \n",
      "6   Logistic Regression (BoW full)     whitespace_noise      2408   \n",
      "21      Random Forest (chi2 k=500)               base64      2408   \n",
      "26      Random Forest (chi2 k=500)            urlencode      2408   \n",
      "25      Random Forest (chi2 k=500)  html_then_urlencode      2408   \n",
      "23      Random Forest (chi2 k=500)     double_urlencode      2408   \n",
      "22      Random Forest (chi2 k=500)       comment_marker      2408   \n",
      "27      Random Forest (chi2 k=500)     whitespace_noise      2408   \n",
      "24      Random Forest (chi2 k=500)        html_entities      2408   \n",
      "\n",
      "    n_malicious     acc    prec     rec      f1  mal_recall  \n",
      "14          814  0.7418  0.0000  0.0000  0.0000      0.0000  \n",
      "19          841  0.7381  0.3077  0.0095  0.0185      0.0095  \n",
      "18          498  0.8245  0.2500  0.0120  0.0230      0.0120  \n",
      "16          479  0.8299  0.2500  0.0125  0.0239      0.0125  \n",
      "15          459  0.9766  0.9579  0.8932  0.9245      0.8932  \n",
      "20          644  0.9921  0.9726  0.9907  0.9815      0.9907  \n",
      "17          657  0.9928  0.9732  0.9939  0.9834      0.9939  \n",
      "7           814  0.7455  0.0000  0.0000  0.0000      0.0000  \n",
      "12          841  0.7424  0.6250  0.0119  0.0233      0.0119  \n",
      "11          498  0.8286  0.5000  0.0120  0.0235      0.0120  \n",
      "9           479  0.8348  0.5714  0.0167  0.0325      0.0167  \n",
      "8           459  0.9944  0.9868  0.9782  0.9825      0.9782  \n",
      "13          644  0.9971  0.9907  0.9953  0.9930      0.9953  \n",
      "10          657  0.9971  0.9909  0.9954  0.9932      0.9954  \n",
      "0           814  0.7455  0.0000  0.0000  0.0000      0.0000  \n",
      "4           498  0.8269  0.1429  0.0020  0.0040      0.0020  \n",
      "2           479  0.8327  0.2500  0.0042  0.0082      0.0042  \n",
      "5           841  0.7421  0.6000  0.0107  0.0210      0.0107  \n",
      "1           459  0.9948  0.9868  0.9804  0.9836      0.9804  \n",
      "3           657  0.9964  0.9909  0.9924  0.9916      0.9924  \n",
      "6           644  0.9977  0.9908  0.9984  0.9946      0.9984  \n",
      "21          814  0.7446  0.0000  0.0000  0.0000      0.0000  \n",
      "26          841  0.7402  0.4000  0.0071  0.0140      0.0071  \n",
      "25          498  0.8273  0.3571  0.0100  0.0195      0.0100  \n",
      "23          479  0.8327  0.3571  0.0104  0.0203      0.0104  \n",
      "22          459  0.9923  0.9802  0.9717  0.9759      0.9717  \n",
      "27          644  0.9957  0.9861  0.9938  0.9899      0.9938  \n",
      "24          657  0.9961  0.9864  0.9954  0.9909      0.9954  \n",
      "Worst technique per model (min malicious recall)                             model worst_technique  mal_recall   f1  \\\n",
      "0      Decision Tree (chi2 k=500)          base64         0.0  0.0   \n",
      "1           Linear SVM (BoW full)          base64         0.0  0.0   \n",
      "2  Logistic Regression (BoW full)          base64         0.0  0.0   \n",
      "3      Random Forest (chi2 k=500)          base64         0.0  0.0   \n",
      "\n",
      "   n_malicious  \n",
      "0          814  \n",
      "1          814  \n",
      "2          814  \n",
      "3          814  \n",
      "Malicious recall pivot by technique (higher is better) model                Decision Tree (chi2 k=500)  Linear SVM (BoW full)  \\\n",
      "technique                                                                \n",
      "base64                                   0.0000                 0.0000   \n",
      "comment_marker                           0.8932                 0.9782   \n",
      "double_urlencode                         0.0125                 0.0167   \n",
      "html_entities                            0.9939                 0.9954   \n",
      "html_then_urlencode                      0.0120                 0.0120   \n",
      "urlencode                                0.0095                 0.0119   \n",
      "whitespace_noise                         0.9907                 0.9953   \n",
      "\n",
      "model                Logistic Regression (BoW full)  \\\n",
      "technique                                             \n",
      "base64                                       0.0000   \n",
      "comment_marker                               0.9804   \n",
      "double_urlencode                             0.0042   \n",
      "html_entities                                0.9924   \n",
      "html_then_urlencode                          0.0020   \n",
      "urlencode                                    0.0107   \n",
      "whitespace_noise                             0.9984   \n",
      "\n",
      "model                Random Forest (chi2 k=500)  \n",
      "technique                                        \n",
      "base64                                   0.0000  \n",
      "comment_marker                           0.9717  \n",
      "double_urlencode                         0.0104  \n",
      "html_entities                            0.9954  \n",
      "html_then_urlencode                      0.0100  \n",
      "urlencode                                0.0071  \n",
      "whitespace_noise                         0.9938  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Dataset\\\\obfuscated_predicted_output\\\\obf_eval_mean.csv',\n",
       " 'Dataset\\\\obfuscated_predicted_output\\\\obf_eval_worst.csv',\n",
       " 'Dataset\\\\obfuscated_predicted_output\\\\obf_eval_per_technique.csv')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format for presentation: round metrics\n",
    "df_mean_fmt = df_mean.copy()\n",
    "df_worst_fmt = df_worst.copy()\n",
    "df_tech_fmt = df_tech.copy()\n",
    "df_worst_tech_fmt = df_worst_tech.copy()\n",
    "pivot_recall_fmt = pivot_recall.copy()\n",
    "\n",
    "for d in [df_mean_fmt, df_worst_fmt, df_tech_fmt, df_worst_tech_fmt, pivot_recall_fmt]:\n",
    "    for col in d.columns:\n",
    "        if d[col].dtype.kind in \"fc\":\n",
    "            d[col] = d[col].astype(float)\n",
    "\n",
    "df_mean_fmt = df_mean_fmt.assign(**{c: df_mean_fmt[c].round(4) for c in [\"acc\",\"prec\",\"rec\",\"f1\"]})\n",
    "df_worst_fmt = df_worst_fmt.assign(**{c: df_worst_fmt[c].round(4) for c in [\"acc\",\"prec\",\"rec\",\"f1\",\"avg_variants\"]})\n",
    "df_tech_fmt = df_tech_fmt.assign(**{c: df_tech_fmt[c].round(4) for c in [\"acc\",\"prec\",\"rec\",\"f1\",\"mal_recall\"]})\n",
    "df_worst_tech_fmt[\"mal_recall\"] = df_worst_tech_fmt[\"mal_recall\"].round(4)\n",
    "df_worst_tech_fmt[\"f1\"] = df_worst_tech_fmt[\"f1\"].round(4)\n",
    "pivot_recall_fmt = pivot_recall_fmt.round(4)\n",
    "\n",
    "print(\"Mean metrics over all obfuscated variants (expanded test)\", df_mean_fmt)\n",
    "print(\"Worst-case robustness (per original sample_id; malicious must pass all variants)\", df_worst_fmt)\n",
    "print(\"Per-technique breakdown (benign + malicious of that technique)\", df_tech_fmt.sort_values([\"model\",\"mal_recall\"]))\n",
    "print(\"Worst technique per model (min malicious recall)\", df_worst_tech_fmt)\n",
    "print(\"Malicious recall pivot by technique (higher is better)\", pivot_recall_fmt)\n",
    "\n",
    "(out_mean_path := Path(\"./Dataset/obfuscated_predicted_output/obf_eval_mean.csv\")).write_text(df_mean_fmt.to_csv(index=False), encoding=\"utf-8\")\n",
    "(out_worst_path := Path(\"./Dataset/obfuscated_predicted_output/obf_eval_worst.csv\")).write_text(df_worst_fmt.to_csv(index=False), encoding=\"utf-8\")\n",
    "(out_tech_path := Path(\"./Dataset/obfuscated_predicted_output/obf_eval_per_technique.csv\")).write_text(df_tech_fmt.to_csv(index=False), encoding=\"utf-8\")\n",
    "(str(out_mean_path), str(out_worst_path), str(out_tech_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a215b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Dataset\\\\obfuscated_predicted_output\\\\obf_mean_metrics.png',\n",
       " 'Dataset\\\\obfuscated_predicted_output\\\\obf_worst_metrics.png',\n",
       " True,\n",
       " True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_grouped_metrics(df, metric_cols, metric_labels, title, out_path,\n",
    "                         y_min=None, y_max=1.0, y_ticks=None, decimals=4):\n",
    "    models = df[\"model\"].tolist()\n",
    "    data = df[metric_cols].to_numpy(dtype=float)\n",
    "\n",
    "    # fixed y limits / ticks\n",
    "    if y_min is None:\n",
    "        vmin = float(np.min(data))\n",
    "        pad = max(1e-4, (y_max - vmin) * 0.15)\n",
    "        y_min = max(0.0, vmin - pad)\n",
    "\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.18\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    containers = []\n",
    "    for i, lab in enumerate(metric_labels):\n",
    "        vals = data[:, i]\n",
    "        bars = ax.bar(x + (i - 1.5) * width, vals, width, label=lab)\n",
    "        containers.append((bars, vals))\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([m.upper() for m in models], fontsize=9)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    if y_ticks is not None:\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_yticklabels([f\"{t:.3f}\" for t in y_ticks])\n",
    "    ax.grid(axis=\"y\", alpha=0.35)\n",
    "    ax.legend(loc=\"upper center\", ncol=4, bbox_to_anchor=(0.5, 1.18))\n",
    "\n",
    "    fmt = \"{:.\" + str(decimals) + \"f}\"\n",
    "    for bars, vals in containers:\n",
    "        for b, v in zip(bars, vals):\n",
    "            ax.text(b.get_x() + b.get_width()/2, v, fmt.format(v),\n",
    "                    ha=\"center\", va=\"bottom\", fontsize=9, rotation=0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "# Metrics like Section 3.1\n",
    "metric_cols = [\"acc\",\"prec\",\"rec\",\"f1\"]\n",
    "metric_labels = [\"Accuracy\",\"Precision\",\"Recall\",\"F1\"]\n",
    "\n",
    "out1 = plot_grouped_metrics(\n",
    "    df_mean, metric_cols, metric_labels,\n",
    "    title=\"Obfuscated XSS (Mean over variants) — Metrics by Model\",\n",
    "    out_path=Path(\"./Dataset/obfuscated_predicted_output/obf_mean_metrics.png\"),\n",
    "    y_max=1.0, y_min=0.0,  # show full range because recall is much lower\n",
    "    y_ticks=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "    decimals=4\n",
    ")\n",
    "\n",
    "out2 = plot_grouped_metrics(\n",
    "    df_worst, metric_cols, metric_labels,\n",
    "    title=\"Obfuscated XSS (Worst-case robustness) — Metrics by Model\",\n",
    "    out_path=Path(\"./Dataset/obfuscated_predicted_output/obf_worst_metrics.png\"),\n",
    "    y_max=1.0, y_min=0.0,\n",
    "    y_ticks=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "    decimals=4\n",
    ")\n",
    "\n",
    "(str(out1), str(out2), Path(out1).exists(), Path(out2).exists())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b4ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
