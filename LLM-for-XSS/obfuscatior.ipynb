{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60bde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d86ab5444843e2b86dd75897651c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c5f3b6c6f447ac9bb02c3dd40cc782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16664\\17849771.py:221: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.377659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.781147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.781147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./codet5_safe_obfuscator\n",
      "\n",
      "Generated SAFE obfuscations:\n",
      "1. console.log('demo',console.colors.green(demo.toString().join('|'))));console.log(demo.name).slice(0, 5).join('')\n",
      "2. // console.log('Hello world...'); // console.log('Launching...');//console.log('Hello World World?');\n",
      "3. { t.main.test} ( 'demo:demo'): console.log(template); });console.log('demodemo');\n",
      "4. console.log('demo'); console.log('demo'); console.log('demo'); console.log('demo'); console.log('demo'); console.log('demo'); console.log('demo');\n"
     ]
    }
   ],
   "source": [
    "# llm_obfuscator_safe.py\n",
    "# Defensive research pipeline: fine-tune CodeT5 to generate obfuscated *SAFE* JavaScript.\n",
    "# NOTE: This script intentionally neutralizes dangerous patterns and blocks risky tokens.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import random\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Safety / Neutralization\n",
    "# -----------------------------\n",
    "DANGEROUS_PATTERNS = [\n",
    "    r\"\\beval\\s*\\(\",\n",
    "    r\"\\bFunction\\s*\\(\",\n",
    "    r\"\\bdocument\\b\",\n",
    "    r\"\\bwindow\\b\",\n",
    "    r\"\\bcookie\\b\",\n",
    "    r\"\\blocation\\b\",\n",
    "    r\"<\\s*script\\b\",\n",
    "    r\"\\bon\\w+\\s*=\",\n",
    "    r\"javascript\\s*:\",\n",
    "    r\"\\batob\\s*\\(\",\n",
    "    r\"\\bdecodeURIComponent\\s*\\(\",\n",
    "]\n",
    "\n",
    "BLOCKED_SUBSTRINGS = [\n",
    "    \"eval\", \"Function\", \"document\", \"cookie\", \"<\", \">\", \"onerror\", \"onload\", \"javascript:\"\n",
    "]\n",
    "\n",
    "def neutralize_js(js: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert input into SAFE JS-like text.\n",
    "    - Removes/rewrites known dangerous tokens\n",
    "    - Ensures we're training an obfuscator, not generating exploit payloads\n",
    "    \"\"\"\n",
    "    s = js.strip()\n",
    "    s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # Rewrite common sink-like identifiers into safe placeholders\n",
    "    s = re.sub(r\"\\balert\\s*\\(\", \"SAFE_CALL(\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\bprompt\\s*\\(\", \"SAFE_CALL(\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\bconfirm\\s*\\(\", \"SAFE_CALL(\", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # Strip angle brackets to avoid HTML/JS injection forms\n",
    "    s = s.replace(\"<\", \" \").replace(\">\", \" \")\n",
    "\n",
    "    # Remove dangerous patterns\n",
    "    for pat in DANGEROUS_PATTERNS:\n",
    "        s = re.sub(pat, \"SAFE_BLOCKED(\", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # Final cleanup\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Obfuscation transforms (safe)\n",
    "#    These mirror the paper's idea but remain non-executable / neutralized.\n",
    "# -----------------------------\n",
    "def obf_string_split(s: str) -> str:\n",
    "    # Split into chunks and concatenate (classic string-splitting idea)\n",
    "    if len(s) < 8:\n",
    "        return f'\"{s}\"'\n",
    "    k = random.randint(3, 6)\n",
    "    parts = []\n",
    "    step = max(1, len(s) // k)\n",
    "    for i in range(0, len(s), step):\n",
    "        parts.append(s[i:i+step])\n",
    "    parts = [p.replace('\"', '\\\\\"') for p in parts]\n",
    "    return \" + \".join([f'\"{p}\"' for p in parts])\n",
    "\n",
    "def obf_whitespace_noise(js: str) -> str:\n",
    "    # Insert benign whitespace/no-op comments\n",
    "    tokens = js.split(\" \")\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        out.append(t)\n",
    "        if random.random() < 0.25:\n",
    "            out.append(\"/*noop*/\")\n",
    "        if random.random() < 0.15:\n",
    "            out.append(\" \")\n",
    "    return \" \".join(out)\n",
    "\n",
    "def obf_keyword_rename_like(js: str) -> str:\n",
    "    # Very light, safe \"rename-like\" obfuscation (doesn't change semantics, just adds aliases)\n",
    "    # We avoid true renaming to keep it simple & safe.\n",
    "    alias = \"v\" + str(random.randint(1000, 9999))\n",
    "    return f\"(function({alias}){{ return {alias}; }})({json.dumps(js)})\"\n",
    "\n",
    "def make_obfuscated_variant(js_safe: str) -> str:\n",
    "    # Randomly apply 1-3 transforms\n",
    "    transforms = [obf_whitespace_noise, obf_keyword_rename_like]\n",
    "    out = js_safe\n",
    "    random.shuffle(transforms)\n",
    "    for fn in transforms[: random.randint(1, 2)]:\n",
    "        out = fn(out)\n",
    "\n",
    "    # Optional string-splitting wrapper to obscure plain text\n",
    "    if random.random() < 0.6:\n",
    "        out = f\"const PAYLOAD = {obf_string_split(out)}; /*SAFE*/\"\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Optional: JS parse validation (AST)\n",
    "# -----------------------------\n",
    "def js_parses_ok(js: str) -> bool:\n",
    "    \"\"\"\n",
    "    Optional validation using node + esprima.\n",
    "    Install:\n",
    "      npm i esprima\n",
    "    Then ensure `node` is available.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse as a script; we wrap in a harmless context.\n",
    "        payload = f\"const x = 1; {js}\"\n",
    "        cmd = [\"node\", \"-e\", \"const esprima=require('esprima'); esprima.parseScript(process.argv[1]);\", payload]\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Dataset builder\n",
    "# -----------------------------\n",
    "def build_pairs(benign_js_list: List[str], n_per_sample: int = 2, require_parse: bool = False) -> Dataset:\n",
    "    rows = []\n",
    "    for js in benign_js_list:\n",
    "        src = neutralize_js(js)\n",
    "        if not src:\n",
    "            continue\n",
    "        for _ in range(n_per_sample):\n",
    "            tgt = make_obfuscated_variant(src)\n",
    "            if require_parse and (not js_parses_ok(tgt)):\n",
    "                continue\n",
    "            rows.append({\"src\": src, \"tgt\": tgt})\n",
    "\n",
    "    # Dedupe\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    for r in rows:\n",
    "        h = hashlib.sha256((r[\"src\"] + \"||\" + r[\"tgt\"]).encode(\"utf-8\")).hexdigest()\n",
    "        if h in seen:\n",
    "            continue\n",
    "        seen.add(h)\n",
    "        deduped.append(r)\n",
    "\n",
    "    return Dataset.from_list(deduped)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Tokenization\n",
    "# -----------------------------\n",
    "def tokenize_function(examples, tokenizer, max_src=256, max_tgt=256):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"src\"],\n",
    "        max_length=max_src,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"tgt\"],\n",
    "        max_length=max_tgt,\n",
    "        truncation=True,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Training\n",
    "# -----------------------------\n",
    "def train_obfuscator(\n",
    "    benign_js_list: List[str],\n",
    "    model_name: str = \"Salesforce/codet5-small\",\n",
    "    out_dir: str = \"./codet5_safe_obfuscator\",\n",
    "    seed: int = 42,\n",
    "    require_parse: bool = False,\n",
    "):\n",
    "    set_seed(seed)\n",
    "\n",
    "    ds = build_pairs(benign_js_list, n_per_sample=3, require_parse=require_parse)\n",
    "    ds = ds.train_test_split(test_size=0.1, seed=seed)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    tokenized_train = ds[\"train\"].map(lambda x: tokenize_function(x, tokenizer), batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "    tokenized_eval  = ds[\"test\"].map(lambda x: tokenize_function(x, tokenizer), batched=True, remove_columns=ds[\"test\"].column_names)\n",
    "\n",
    "    collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(out_dir)\n",
    "    tokenizer.save_pretrained(out_dir)\n",
    "    print(f\"Saved to: {out_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Safe generation with filtering (temperature/top_p)\n",
    "# -----------------------------\n",
    "def safe_generate(\n",
    "    text: str,\n",
    "    ckpt_dir: str = \"./codet5_safe_obfuscator\",\n",
    "    num_samples: int = 5,\n",
    "    temperature: float = 1.2,\n",
    "    top_p: float = 0.95,\n",
    "    max_new_tokens: int = 180,\n",
    ") -> List[str]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(ckpt_dir)\n",
    "    model.eval()\n",
    "\n",
    "    src = neutralize_js(text)\n",
    "    inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            gen_ids = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_beams=1,\n",
    "            )\n",
    "            s = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            # Block risky substrings defensively\n",
    "            low = s.lower()\n",
    "            if any(b.lower() in low for b in BLOCKED_SUBSTRINGS):\n",
    "                continue\n",
    "\n",
    "            # Remove any accidental brackets again\n",
    "            s = s.replace(\"<\", \" \").replace(\">\", \" \")\n",
    "            s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "            outputs.append(s)\n",
    "\n",
    "    # Dedupe\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for o in outputs:\n",
    "        h = hashlib.md5(o.encode(\"utf-8\")).hexdigest()\n",
    "        if h not in seen:\n",
    "            seen.add(h)\n",
    "            uniq.append(o)\n",
    "    return uniq\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Example usage\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide benign JS snippets only (or your \"neutralized\" dataset)\n",
    "    benign_examples = [\n",
    "        \"function add(a,b){ return a+b; } console.log(add(2,3));\",\n",
    "        \"const msg = 'hello world'; console.log(msg.toUpperCase());\",\n",
    "        \"if (x > 10) { console.log('big'); } else { console.log('small'); }\",\n",
    "    ]\n",
    "\n",
    "    # 1) Train\n",
    "    train_obfuscator(benign_examples, require_parse=False)\n",
    "\n",
    "    # 2) Generate safe obfuscations\n",
    "    outs = safe_generate(\"console.log('demo');\", num_samples=6, temperature=1.3, top_p=0.9)\n",
    "    print(\"\\nGenerated SAFE obfuscations:\")\n",
    "    for i, o in enumerate(outs, 1):\n",
    "        print(f\"{i}. {o}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086dc018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
